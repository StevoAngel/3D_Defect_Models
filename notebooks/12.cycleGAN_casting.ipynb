{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1247a75a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used: NVIDIA GeForce RTX 5080\n",
      "Classes found: {'def_front': 0, 'ok_front': 1}\n",
      "Domain A (Good) images: 2875\n",
      "Domain B (Defect) images: 3758\n",
      "[0/50] Loss_G: 36.0320 Loss_D: 19.9476\n",
      "[1/50] Loss_G: 16.8887 Loss_D: 3.4917\n",
      "[2/50] Loss_G: 14.5513 Loss_D: 2.1973\n",
      "[3/50] Loss_G: 12.3174 Loss_D: 1.3768\n",
      "[4/50] Loss_G: 10.4103 Loss_D: 1.9147\n",
      "[5/50] Loss_G: 7.2716 Loss_D: 0.6264\n",
      "[6/50] Loss_G: 6.5894 Loss_D: 0.7915\n",
      "[7/50] Loss_G: 6.2022 Loss_D: 0.7059\n",
      "[8/50] Loss_G: 6.0760 Loss_D: 0.7542\n",
      "[9/50] Loss_G: 5.8870 Loss_D: 0.7373\n",
      "[10/50] Loss_G: 5.6783 Loss_D: 0.6622\n",
      "[11/50] Loss_G: 5.4188 Loss_D: 0.6634\n",
      "[12/50] Loss_G: 5.3609 Loss_D: 0.7897\n",
      "[13/50] Loss_G: 4.9059 Loss_D: 0.6043\n",
      "[14/50] Loss_G: 4.8377 Loss_D: 0.7393\n",
      "[15/50] Loss_G: 4.5992 Loss_D: 0.6725\n",
      "[16/50] Loss_G: 4.4612 Loss_D: 0.6570\n",
      "[17/50] Loss_G: 4.3261 Loss_D: 0.6548\n",
      "[18/50] Loss_G: 4.5677 Loss_D: 0.7003\n",
      "[19/50] Loss_G: 4.1818 Loss_D: 0.6151\n",
      "[20/50] Loss_G: 4.0979 Loss_D: 0.6513\n",
      "[21/50] Loss_G: 4.1008 Loss_D: 0.7706\n",
      "[22/50] Loss_G: 3.9398 Loss_D: 0.5669\n",
      "[23/50] Loss_G: 3.9562 Loss_D: 0.6520\n",
      "[24/50] Loss_G: 3.8042 Loss_D: 0.6018\n",
      "[25/50] Loss_G: 3.8501 Loss_D: 0.6399\n",
      "[26/50] Loss_G: 3.7688 Loss_D: 0.5982\n",
      "[27/50] Loss_G: 3.7981 Loss_D: 0.6368\n",
      "[28/50] Loss_G: 3.7237 Loss_D: 0.6176\n",
      "[29/50] Loss_G: 3.6478 Loss_D: 0.6046\n",
      "[30/50] Loss_G: 3.5758 Loss_D: 0.5485\n",
      "[31/50] Loss_G: 3.5513 Loss_D: 0.6818\n",
      "[32/50] Loss_G: 3.4413 Loss_D: 0.5434\n",
      "[33/50] Loss_G: 3.5002 Loss_D: 0.6195\n",
      "[34/50] Loss_G: 3.5162 Loss_D: 0.6582\n",
      "[35/50] Loss_G: 3.2835 Loss_D: 0.5060\n",
      "[36/50] Loss_G: 3.3191 Loss_D: 0.5329\n",
      "[37/50] Loss_G: 3.2962 Loss_D: 0.5560\n",
      "[38/50] Loss_G: 6.5223 Loss_D: 1.4675\n",
      "[39/50] Loss_G: 4.3750 Loss_D: 0.3929\n",
      "[40/50] Loss_G: 4.1501 Loss_D: 0.6235\n",
      "[41/50] Loss_G: 3.6482 Loss_D: 0.4110\n",
      "[42/50] Loss_G: 3.5637 Loss_D: 0.4028\n",
      "[43/50] Loss_G: 3.5739 Loss_D: 0.4353\n",
      "[44/50] Loss_G: 3.4546 Loss_D: 0.4296\n",
      "[45/50] Loss_G: 3.4030 Loss_D: 0.4349\n",
      "[46/50] Loss_G: 3.4212 Loss_D: 0.5281\n",
      "[47/50] Loss_G: 3.4428 Loss_D: 0.4685\n",
      "[48/50] Loss_G: 3.3485 Loss_D: 0.4479\n",
      "[49/50] Loss_G: 3.3045 Loss_D: 0.4589\n",
      "CycleGAN Training Completed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import itertools\n",
    "import torch\n",
    "import torchvision\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as T\n",
    "import torch.nn as NN\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "# Detecting if a GPU is available:\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device used: {torch.cuda.get_device_name(0)}\") if device == \"cuda\" else print(\"No GPU available: Using CPU\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. NEW ARCHITECTURE: CycleGenerator (Encoder-Decoder)\n",
    "# Adapted from your DCGAN layers but mirrored to handle Image-to-Image translation\n",
    "# ==============================================================================\n",
    "class CycleGenerator(NN.Module):\n",
    "    def __init__(self, nc, ngf):\n",
    "        super(CycleGenerator, self).__init__()\n",
    "        \n",
    "        # --- Encoder (Downsampling) ---\n",
    "        # Similar to your Discriminator structure\n",
    "        self.e1 = NN.Sequential(NN.Conv2d(nc, ngf, 4, 2, 1, bias=False), NN.LeakyReLU(0.2, inplace=True))\n",
    "        self.e2 = NN.Sequential(NN.Conv2d(ngf, ngf * 2, 4, 2, 1, bias=False), NN.BatchNorm2d(ngf * 2), NN.LeakyReLU(0.2, inplace=True))\n",
    "        self.e3 = NN.Sequential(NN.Conv2d(ngf * 2, ngf * 4, 4, 2, 1, bias=False), NN.BatchNorm2d(ngf * 4), NN.LeakyReLU(0.2, inplace=True))\n",
    "        self.e4 = NN.Sequential(NN.Conv2d(ngf * 4, ngf * 8, 4, 2, 1, bias=False), NN.BatchNorm2d(ngf * 8), NN.LeakyReLU(0.2, inplace=True))\n",
    "        \n",
    "        # Bottleneck (Latent representation of the image)\n",
    "        self.b1 = NN.Sequential(NN.Conv2d(ngf * 8, ngf * 8, 4, 1, 1, bias=False), NN.ReLU(True)) # Just passing through\n",
    "\n",
    "        # --- Decoder (Upsampling) ---\n",
    "        # Similar to your original Generator structure\n",
    "        self.d1 = NN.Sequential(NN.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False), NN.BatchNorm2d(ngf * 4), NN.ReLU(True))\n",
    "        self.d2 = NN.Sequential(NN.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False), NN.BatchNorm2d(ngf * 2), NN.ReLU(True))\n",
    "        self.d3 = NN.Sequential(NN.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False), NN.BatchNorm2d(ngf), NN.ReLU(True))\n",
    "        \n",
    "        # Final Output\n",
    "        self.d4 = NN.Sequential(NN.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False), NN.Tanh())\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        x1 = self.e1(x)\n",
    "        x2 = self.e2(x1)\n",
    "        x3 = self.e3(x2)\n",
    "        x4 = self.e4(x3)\n",
    "        \n",
    "        # Decoder (Ideally with Skip Connections like U-Net, but keeping it simple as Autoencoder for your structure)\n",
    "        d1 = self.d1(x4) \n",
    "        d2 = self.d2(d1)\n",
    "        d3 = self.d3(d2)\n",
    "        out = self.d4(d3)\n",
    "        return out\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. DISCRIMINATOR (Kept exactly as your DCGAN Discriminator)\n",
    "# ==============================================================================\n",
    "class Discriminator(NN.Module):\n",
    "    def __init__(self, nc, ndf):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = NN.Sequential(\n",
    "            # Input is 128 x 128\n",
    "            NN.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            NN.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            NN.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            NN.BatchNorm2d(ndf * 2),\n",
    "            NN.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            NN.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            NN.BatchNorm2d(ndf * 4),\n",
    "            NN.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            NN.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            NN.BatchNorm2d(ndf * 8),\n",
    "            NN.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            NN.Conv2d(ndf * 8, ndf * 16, 4, 2, 1, bias=False), # Handling 128x128 depth\n",
    "            NN.BatchNorm2d(ndf * 16),\n",
    "            NN.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            NN.Conv2d(ndf * 16, 1, 4, 1, 0, bias=False)\n",
    "            # No Sigmoid because we will use MSELoss (LSGAN is standard for CycleGAN)\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "\n",
    "# Weights init function:\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        NN.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        NN.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        NN.init.constant_(m.bias.data, 0)\n",
    "\n",
    "# Helper to manage image buffer (CycleGAN stability trick)\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, max_size=50):\n",
    "        self.max_size = max_size\n",
    "        self.data = []\n",
    "\n",
    "    def push_and_pop(self, data):\n",
    "        to_return = []\n",
    "        for element in data.data:\n",
    "            element = torch.unsqueeze(element, 0)\n",
    "            if len(self.data) < self.max_size:\n",
    "                self.data.append(element)\n",
    "                to_return.append(element)\n",
    "            else:\n",
    "                if random.uniform(0, 1) > 0.5:\n",
    "                    i = random.randint(0, self.max_size - 1)\n",
    "                    to_return.append(self.data[i].clone())\n",
    "                    self.data[i] = element\n",
    "                else:\n",
    "                    to_return.append(element)\n",
    "        return torch.cat(to_return)\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. TRAINING LOOP ADAPTED FOR CYCLEGAN\n",
    "# ==============================================================================\n",
    "def train_cycle_epoch(dataloader_A, dataloader_B, netG_A2B, netG_B2A, netD_A, netD_B, \n",
    "                      criterion_GAN, criterion_Cycle, optimizerG, optimizerD, device, lambda_cycle):\n",
    "\n",
    "    # Metric acumulators:\n",
    "    running_loss_G = 0.0\n",
    "    running_loss_D = 0.0\n",
    "    \n",
    "    # Fake Image Buffers\n",
    "    fake_A_buffer = ReplayBuffer()\n",
    "    fake_B_buffer = ReplayBuffer()\n",
    "\n",
    "    # Zip the two dataloaders to get pairs (unpaired) in each step\n",
    "    # Make sure both dataloaders have drop_last=True to avoid size mismatch\n",
    "    for i, (data_A, data_B) in enumerate(zip(dataloader_A, dataloader_B)):\n",
    "        \n",
    "        real_A = data_A[0].to(device)\n",
    "        real_B = data_B[0].to(device)\n",
    "        b_size = real_A.size(0)\n",
    "\n",
    "        # Labels for LSGAN (MSE Loss)\n",
    "        # Real = 1.0, Fake = 0.0\n",
    "        target_real = torch.full((b_size,), 1.0, device=device, requires_grad=False)\n",
    "        target_fake = torch.full((b_size,), 0.0, device=device, requires_grad=False)\n",
    "\n",
    "        # --------------------------------------------------\n",
    "        # Update Generators (G_A2B and G_B2A)\n",
    "        # --------------------------------------------------\n",
    "        optimizerG.zero_grad()\n",
    "\n",
    "        # 1. Identity Loss (Optional but good for preserving colors/shape)\n",
    "        # G_A2B(B) should equal B if we feed it a picture that is already domain B\n",
    "        loss_id_A = criterion_Cycle(netG_B2A(real_A), real_A) * lambda_cycle * 0.5\n",
    "        loss_id_B = criterion_Cycle(netG_A2B(real_B), real_B) * lambda_cycle * 0.5\n",
    "        \n",
    "        # 2. GAN Loss\n",
    "        # GAN Loss D_A(G_A(A))\n",
    "        fake_B = netG_A2B(real_A)\n",
    "        output_fake_B = netD_B(fake_B).view(-1)\n",
    "        loss_GAN_A2B = criterion_GAN(output_fake_B, target_real)\n",
    "\n",
    "        # GAN Loss D_B(G_B(B))\n",
    "        fake_A = netG_B2A(real_B)\n",
    "        output_fake_A = netD_A(fake_A).view(-1)\n",
    "        loss_GAN_B2A = criterion_GAN(output_fake_A, target_real)\n",
    "\n",
    "        # 3. Cycle Consistency Loss\n",
    "        # Forward Cycle: A -> FakeB -> RecA\n",
    "        rec_A = netG_B2A(fake_B)\n",
    "        loss_cycle_A = criterion_Cycle(rec_A, real_A) * lambda_cycle\n",
    "\n",
    "        # Backward Cycle: B -> FakeA -> RecB\n",
    "        rec_B = netG_A2B(fake_A)\n",
    "        loss_cycle_B = criterion_Cycle(rec_B, real_B) * lambda_cycle\n",
    "\n",
    "        # Total Generator Loss\n",
    "        loss_G = loss_GAN_A2B + loss_GAN_B2A + loss_cycle_A + loss_cycle_B + loss_id_A + loss_id_B\n",
    "        loss_G.backward()\n",
    "        optimizerG.step()\n",
    "\n",
    "        # --------------------------------------------------\n",
    "        # Update Discriminators (D_A and D_B)\n",
    "        # --------------------------------------------------\n",
    "        optimizerD.zero_grad()\n",
    "\n",
    "        # Discriminator A\n",
    "        pred_real = netD_A(real_A).view(-1)\n",
    "        loss_D_real = criterion_GAN(pred_real, target_real)\n",
    "        \n",
    "        # Get fake from buffer to stabilize training\n",
    "        fake_A_ = fake_A_buffer.push_and_pop(fake_A)\n",
    "        pred_fake = netD_A(fake_A_.detach()).view(-1)\n",
    "        loss_D_fake = criterion_GAN(pred_fake, target_fake)\n",
    "        loss_D_A = (loss_D_real + loss_D_fake) * 0.5\n",
    "        loss_D_A.backward()\n",
    "\n",
    "        # Discriminator B\n",
    "        pred_real = netD_B(real_B).view(-1)\n",
    "        loss_D_real = criterion_GAN(pred_real, target_real)\n",
    "        \n",
    "        fake_B_ = fake_B_buffer.push_and_pop(fake_B)\n",
    "        pred_fake = netD_B(fake_B_.detach()).view(-1)\n",
    "        loss_D_fake = criterion_GAN(pred_fake, target_fake)\n",
    "        loss_D_B = (loss_D_real + loss_D_fake) * 0.5\n",
    "        loss_D_B.backward()\n",
    "\n",
    "        optimizerD.step()\n",
    "\n",
    "        running_loss_G += loss_G.item()\n",
    "        running_loss_D += (loss_D_A.item() + loss_D_B.item())\n",
    "\n",
    "    n_batches = len(dataloader_A)\n",
    "    return running_loss_G / n_batches, running_loss_D / n_batches\n",
    "\n",
    "# Ploting function for CycleGAN:\n",
    "def plot_cycle_epoch(epoch, netG_A2B, fixed_real_A, plots_filename):\n",
    "    # Generate images:\n",
    "    with torch.no_grad():\n",
    "        # A -> Fake B (Translation)\n",
    "        fake_B = netG_A2B(fixed_real_A).detach().cpu()\n",
    "        \n",
    "    # Show images (Real A vs Fake B)\n",
    "    real_img = fixed_real_A.cpu()\n",
    "    \n",
    "    # Concatenate Real and Generated side by side\n",
    "    combined_grid = torch.cat((real_img[:8], fake_B[:8]), 0) # Show 8 examples\n",
    "\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f\"CycleGAN Epoch {epoch}: Real (Top) -> Defective (Bottom)\")\n",
    "    \n",
    "    plt.imshow(np.transpose(torchvision.utils.make_grid(combined_grid, padding=2, normalize=True, nrow=8).numpy(), (1,2,0)))\n",
    "    \n",
    "    # Create directory if not exists (Safety check)\n",
    "    os.makedirs(os.path.dirname(plots_filename), exist_ok=True)\n",
    "    plt.savefig(plots_filename, bbox_inches='tight') \n",
    "    plt.close()\n",
    "\n",
    "# ==========================================================================\n",
    "# ####### MODEL TRAINING EXECUTION #######\n",
    "# ==========================================================================\n",
    "\n",
    "# MLFLow information:\n",
    "EXPERIMENT_NAME = \"Defect_Generation_On_Manufactured_Pieces\"\n",
    "RUN_NAME = \"Try: CycleGAN for casting-metal pieces for image generation\"\n",
    "\n",
    "# Hyperparameters\n",
    "HP_LR = 0.0002\n",
    "HP_NGF = 64\n",
    "HP_NDF = 64\n",
    "HP_NC = 3 # RGB Images\n",
    "HP_N_EPOCHS = 50 \n",
    "HP_BATCH_SIZE = 16 # CycleGAN uses smaller batches (often 1 or 4, but 16 works for simple cases)\n",
    "HP_LAMBDA_CYCLE = 10.0 # Weight for cycle consistency\n",
    "\n",
    "# Transforming the data (128x128 needed for this deeper architecture):\n",
    "transform = T.Compose([\n",
    "    T.Resize(128),\n",
    "    T.CenterCrop(128),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize([0.5] * 3, [0.5] * 3)\n",
    "])\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# CRITICAL FIX: DATA LOADING STRATEGY\n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "# 1. Point ImageFolder to the PARENT directory containing both subfolders\n",
    "# Structure expected:\n",
    "# .../train/\n",
    "#       ├── ok_front/   (Good pieces)\n",
    "#       └── def_front/  (Defective pieces)\n",
    "root_dir = \"../data/raw/casting/casting_data/casting_data/train\"\n",
    "\n",
    "full_dataset = torchvision.datasets.ImageFolder(\n",
    "    root=root_dir, \n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# 2. Identify class mapping\n",
    "# This tells us which integer corresponds to which folder\n",
    "class_map = full_dataset.class_to_idx\n",
    "print(f\"Classes found: {class_map}\") \n",
    "# Expected: {'def_front': 0, 'ok_front': 1} (or vice versa, code handles it dynamically)\n",
    "\n",
    "idx_ok = class_map['ok_front']\n",
    "idx_def = class_map['def_front']\n",
    "\n",
    "# 3. Filter indices to separate domains\n",
    "# We scan the 'targets' list to find which image belongs to which class\n",
    "all_targets = torch.tensor(full_dataset.targets)\n",
    "\n",
    "# Get indices where target == ok_front\n",
    "indices_A = (all_targets == idx_ok).nonzero(as_tuple=True)[0]\n",
    "\n",
    "# Get indices where target == def_front\n",
    "indices_B = (all_targets == idx_def).nonzero(as_tuple=True)[0]\n",
    "\n",
    "# 4. Create Subsets (Virtual independent datasets)\n",
    "dataset_A = torch.utils.data.Subset(full_dataset, indices_A) # Domain A: Good\n",
    "dataset_B = torch.utils.data.Subset(full_dataset, indices_B) # Domain B: Defective\n",
    "\n",
    "print(f\"Domain A (Good) images: {len(dataset_A)}\")\n",
    "print(f\"Domain B (Defect) images: {len(dataset_B)}\")\n",
    "\n",
    "# 5. Create Independent Dataloaders\n",
    "# CycleGAN needs to iterate them separately\n",
    "loader_A = torch.utils.data.DataLoader(dataset_A, batch_size=HP_BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "loader_B = torch.utils.data.DataLoader(dataset_B, batch_size=HP_BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# END OF FIX\n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "# Initialize Models\n",
    "# We need 2 Generators and 2 Discriminators\n",
    "netG_A2B = CycleGenerator(HP_NC, HP_NGF).to(device) # Good -> Defective\n",
    "netG_B2A = CycleGenerator(HP_NC, HP_NGF).to(device) # Defective -> Good\n",
    "netD_A = Discriminator(HP_NC, HP_NDF).to(device)    # Is it real Good?\n",
    "netD_B = Discriminator(HP_NC, HP_NDF).to(device)    # Is it real Defective?\n",
    "\n",
    "# Init weights\n",
    "netG_A2B.apply(weights_init)\n",
    "netG_B2A.apply(weights_init)\n",
    "netD_A.apply(weights_init)\n",
    "netD_B.apply(weights_init)\n",
    "\n",
    "# Loss functions\n",
    "criterion_GAN = NN.MSELoss() # LSGAN\n",
    "criterion_Cycle = NN.L1Loss() # L1 is better for cycle consistency\n",
    "\n",
    "# Optimizers (One for Gs, One for Ds)\n",
    "optimizerG = optim.Adam(itertools.chain(netG_A2B.parameters(), netG_B2A.parameters()), lr=HP_LR, betas=(0.5, 0.999))\n",
    "optimizerD = optim.Adam(itertools.chain(netD_A.parameters(), netD_B.parameters()), lr=HP_LR, betas=(0.5, 0.999))\n",
    "\n",
    "# Training Loop\n",
    "MLFLOW_TRACKING = True\n",
    "\n",
    "if MLFLOW_TRACKING:\n",
    "    mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "    with mlflow.start_run(run_name=RUN_NAME):\n",
    "        \n",
    "        # Log Params\n",
    "        mlflow.log_param('architecture', \"CycleGAN_Custom\")\n",
    "        mlflow.log_param('batch_size', HP_BATCH_SIZE)\n",
    "        mlflow.log_param('lambda_cycle', HP_LAMBDA_CYCLE)\n",
    "\n",
    "        # Fixed sample for visualization (A batch of good parts)\n",
    "        fixed_real_A = next(iter(loader_A))[0].to(device)\n",
    "\n",
    "        for epoch in range(HP_N_EPOCHS):\n",
    "            avg_loss_G, avg_loss_D = train_cycle_epoch(\n",
    "                loader_A, loader_B, \n",
    "                netG_A2B, netG_B2A, netD_A, netD_B, \n",
    "                criterion_GAN, criterion_Cycle, optimizerG, optimizerD, \n",
    "                device, HP_LAMBDA_CYCLE\n",
    "            )\n",
    "\n",
    "            print(f\"[{epoch}/{HP_N_EPOCHS}] Loss_G: {avg_loss_G:.4f} Loss_D: {avg_loss_D:.4f}\")\n",
    "            mlflow.log_metric('loss_g', avg_loss_G, step=epoch)\n",
    "            mlflow.log_metric('loss_d', avg_loss_D, step=epoch)\n",
    "\n",
    "            if epoch % 5 == 0 or epoch == HP_N_EPOCHS - 1:\n",
    "                plots_filename = f\"../reports/figures/CycleGAN/epoch_{epoch}.png\"\n",
    "                plot_cycle_epoch(epoch, netG_A2B, fixed_real_A, plots_filename)\n",
    "                mlflow.log_artifact(plots_filename, 'plots')\n",
    "                # os.remove(plots_filename) # Uncomment to clean up local files\n",
    "\n",
    "        # Save Models (We mainly care about G_A2B: Good -> Defect)\n",
    "        torch.save(netG_A2B.state_dict(), \"../models/netG_A2B.pth\")\n",
    "        mlflow.log_artifact(\"../models/netG_A2B.pth\", \"models\")\n",
    "        print(\"CycleGAN Training Completed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
